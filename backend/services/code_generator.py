"""
Code generator for exporting models as Python PyTorch code
"""
from typing import Dict, Any
from backend.db.models import ModelVersion

class CodeGenerator:
    """Generates Python PyTorch code from model versions"""
    
    def __init__(self, version: ModelVersion):
        self.version = version
    
    def generate_pytorch_code(self, model_name: str = "Model") -> str:
        """Generate complete PyTorch model code"""
        architecture = self.version.architecture
        custom_loss = self.version.custom_loss or "nn.CrossEntropyLoss()"
        
        code = f'''"""
PyTorch Model: {model_name} - Version {self.version.version_number}
Generated by DL Model Builder & Visualizer Platform
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
    """
    Model Architecture:
    {self._format_architecture(architecture)}
    """
    
    def __init__(self):
        super(Model, self).__init__()
        
{self._generate_init_code(architecture)}
    
    def forward(self, x):
{self._generate_forward_code(architecture)}
        return x


# Custom Loss Function
def get_loss_function():
    """
    Custom loss function for this model
    """
    return {custom_loss}


# Example usage
if __name__ == "__main__":
    # Create model instance
    model = Model()
    
    # Print model architecture
    print(model)
    
    # Example input
    input_shape = {self.version.input_shape}
    example_input = torch.randn(*input_shape)
    
    # Forward pass
    output = model(example_input)
    print(f"Input shape: {{example_input.shape}}")
    print(f"Output shape: {{output.shape}}")
    
    # Loss function
    loss_fn = get_loss_function()
    print(f"Loss function: {{loss_fn}}")
'''
        return code
    
    def _format_architecture(self, architecture: Dict[str, Any]) -> str:
        """Format architecture for docstring"""
        layers = architecture.get("layers", [])
        lines = []
        for i, layer in enumerate(layers):
            layer_type = layer.get("type", "Unknown")
            params = layer.get("params", {})
            lines.append(f"  {i+1}. {layer_type}({self._format_params(params)})")
        return "\n".join(lines) if lines else "  No layers defined"
    
    def _format_params(self, params: Dict[str, Any]) -> str:
        """Format parameters for display"""
        return ", ".join([f"{k}={v}" for k, v in params.items()])
    
    def _generate_init_code(self, architecture: Dict[str, Any]) -> str:
        """Generate __init__ method code"""
        layers = architecture.get("layers", [])
        lines = []
        
        for i, layer in enumerate(layers):
            layer_type = layer.get("type")
            params = layer.get("params", {})
            var_name = f"layer_{i}"
            
            if layer_type == "Conv2d":
                lines.append(f"        self.{var_name} = nn.Conv2d(")
                lines.append(f"            in_channels={params.get('in_channels', 3)},")
                lines.append(f"            out_channels={params.get('out_channels', 64)},")
                lines.append(f"            kernel_size={params.get('kernel_size', 3)},")
                lines.append(f"            stride={params.get('stride', 1)},")
                lines.append(f"            padding={params.get('padding', 0)})")
            
            elif layer_type in ["Dense", "Linear"]:
                lines.append(f"        self.{var_name} = nn.Linear(")
                lines.append(f"            in_features={params.get('in_features', 128)},")
                lines.append(f"            out_features={params.get('out_features', 64)})")
            
            elif layer_type == "MaxPool2d":
                lines.append(f"        self.{var_name} = nn.MaxPool2d(")
                lines.append(f"            kernel_size={params.get('kernel_size', 2)},")
                lines.append(f"            stride={params.get('stride', 2)})")
            
            elif layer_type == "AvgPool2d":
                lines.append(f"        self.{var_name} = nn.AvgPool2d(")
                lines.append(f"            kernel_size={params.get('kernel_size', 2)},")
                lines.append(f"            stride={params.get('stride', 2)})")
            
            elif layer_type == "BatchNorm2d":
                lines.append(f"        self.{var_name} = nn.BatchNorm2d(")
                lines.append(f"            num_features={params.get('num_features', 64)})")
            
            elif layer_type == "ReLU":
                lines.append(f"        self.{var_name} = nn.ReLU()")
            
            elif layer_type == "Sigmoid":
                lines.append(f"        self.{var_name} = nn.Sigmoid()")
            
            elif layer_type == "Tanh":
                lines.append(f"        self.{var_name} = nn.Tanh()")
            
            elif layer_type == "Dropout":
                lines.append(f"        self.{var_name} = nn.Dropout(")
                lines.append(f"            p={params.get('p', 0.5)})")
            
            elif layer_type == "Flatten":
                lines.append(f"        self.{var_name} = nn.Flatten()")
            
            elif layer_type == "AdaptiveAvgPool2d":
                lines.append(f"        self.{var_name} = nn.AdaptiveAvgPool2d(")
                lines.append(f"            output_size={params.get('output_size', (1, 1))})")
        
        return "\n".join(lines) if lines else "        pass"
    
    def _generate_forward_code(self, architecture: Dict[str, Any]) -> str:
        """Generate forward method code"""
        layers = architecture.get("layers", [])
        lines = []
        
        for i, layer in enumerate(layers):
            var_name = f"layer_{i}"
            lines.append(f"        x = self.{var_name}(x)")
        
        return "\n".join(lines) if lines else "        pass"

