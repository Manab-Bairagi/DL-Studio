# Integration Testing Guide - Inference & Visualization Phase

## üß™ Testing Overview

This document guides you through comprehensive integration testing of the complete inference pipeline.

**Scope**: Backend + Frontend + Database + PyTorch Model

**Duration**: ~30 minutes

**Success Criteria**: 
- ‚úÖ Backend API responds correctly
- ‚úÖ Frontend renders components
- ‚úÖ Image upload works
- ‚úÖ Inference completes successfully
- ‚úÖ Visualizations render properly
- ‚úÖ No console errors

---

## üìã Pre-Testing Checklist

### 1. Verify Backend is Running
```powershell
# Check if uvicorn is running
# Should see: "Uvicorn running on http://127.0.0.1:8000"
```

### 2. Verify Frontend is Running
```powershell
cd e:\Project_X\frontend
npm run dev
# Should see: "Local: http://localhost:5173"
```

### 3. Verify MongoDB Connection
```powershell
# Backend terminal should show no connection errors
# Check: "Successfully connected to MongoDB"
```

### 4. Check Python Environment
```powershell
python -c "import torch, fastapi, PIL; print('‚úÖ All packages OK')"
# Should output: ‚úÖ All packages OK
```

---

## üîß Test 1: Backend Health Check

### Purpose
Verify backend is running and accessible

### Steps
```powershell
# 1. Check API health endpoint
curl http://localhost:8000/api/health

# Expected Response:
# {"status": "ok"}
```

### Expected Result
```
Status: 200 OK
Response: {"status": "ok"}
```

---

## üîë Test 2: Authentication Flow

### Purpose
Verify auth system works (required for inference)

### Steps
```powershell
# 1. Register a test user
curl -X POST http://localhost:8000/api/v1/auth/register `
  -H "Content-Type: application/json" `
  -d '{
    "email": "test@example.com",
    "password": "testpass123",
    "full_name": "Test User"
  }'

# Expected: 
# {"id": "...", "email": "test@example.com"}
```

### 2. Login
```powershell
curl -X POST http://localhost:8000/api/v1/auth/login `
  -H "Content-Type: application/json" `
  -d '{
    "email": "test@example.com",
    "password": "testpass123"
  }'

# Expected Response:
# {
#   "access_token": "eyJ0eXAiOiJKV1QiLCJhbGc...",
#   "token_type": "bearer"
# }
```

### Store Token
```powershell
$TOKEN = "your-token-from-response"
```

### Expected Result
‚úÖ User registered and logged in
‚úÖ Valid JWT token received

---

## üì¶ Test 3: Create Model for Testing

### Purpose
Create a test model to run inference on

### Steps

#### 1. Create Model
```powershell
curl -X POST http://localhost:8000/api/v1/models `
  -H "Content-Type: application/json" `
  -H "Authorization: Bearer $TOKEN" `
  -d '{
    "name": "TestCNN",
    "description": "Test model for inference",
    "model_type": "classification"
  }'

# Expected Response:
# {"id": "65f8c9...", "name": "TestCNN", ...}
```

Save the `id` as `$MODEL_ID`

#### 2. Create Model Version with Architecture
```powershell
curl -X POST http://localhost:8000/api/v1/models/$MODEL_ID/versions `
  -H "Content-Type: application/json" `
  -H "Authorization: Bearer $TOKEN" `
  -d '{
    "architecture": {
      "layers": [
        {"type": "Conv2d", "params": {"in_channels": 3, "out_channels": 32, "kernel_size": 3}},
        {"type": "ReLU", "params": {"inplace": false}},
        {"type": "MaxPool2d", "params": {"kernel_size": 2, "stride": 2}},
        {"type": "Conv2d", "params": {"in_channels": 32, "out_channels": 64, "kernel_size": 3}},
        {"type": "ReLU", "params": {"inplace": false}},
        {"type": "Flatten", "params": {"start_dim": 1}},
        {"type": "Linear", "params": {"in_features": 64, "out_features": 10}}
      ]
    },
    "input_shape": [1, 3, 32, 32],
    "notes": "Simple CNN for CIFAR-10"
  }'

# Expected Response:
# {"id": "...", "version_number": 1, ...}
```

Save the `id` as `$VERSION_ID`

### Expected Result
‚úÖ Model created with valid ID
‚úÖ Version created with architecture
‚úÖ Input shape: [1, 3, 32, 32] (1 batch, 3 channels, 32x32 image)

---

## üß† Test 4: Backend Inference Endpoint

### Purpose
Test inference API with raw data

### Steps

#### 1. Get Model Config
```powershell
curl -X GET http://localhost:8000/api/v1/inference/$VERSION_ID/config `
  -H "Authorization: Bearer $TOKEN"

# Expected Response:
# {
#   "input_shape": [1, 3, 32, 32],
#   "architecture": {...},
#   "total_parameters": 12345,
#   "trainable_parameters": 12345
# }
```

#### 2. Run Inference with Random Data
```powershell
# Generate random input (1 √ó 3 √ó 32 √ó 32 = 3072 values)
$input_data = @(0..3071) | ForEach-Object { Get-Random -Maximum 1.0 }

curl -X POST http://localhost:8000/api/v1/inference/run `
  -H "Content-Type: application/json" `
  -H "Authorization: Bearer $TOKEN" `
  -d @{
    "version_id": "$VERSION_ID"
    "input_data": $input_data.ToList()
  } | ConvertTo-Json

# Expected Response:
# {
#   "version_id": "...",
#   "output": [0.1, 0.2, ..., 0.15],
#   "output_shape": [1, 10],
#   "processing_time": 0.245,
#   "layer_outputs": [
#     {
#       "layer_name": "0",
#       "layer_type": "Conv2d",
#       "output_shape": [1, 32, 30, 30],
#       "activation_stats": {
#         "min": -0.234,
#         "max": 3.456,
#         "mean": 0.567,
#         "std": 0.789,
#         "median": 0.45
#       },
#       "output_data": [...]
#     },
#     ...
#   ]
# }
```

### Expected Result
‚úÖ Inference completes in <1 second
‚úÖ Output shape matches model output
‚úÖ Layer outputs contain statistics
‚úÖ 7 layer outputs (one per layer)

---

## üñºÔ∏è Test 5: Frontend Components Render

### Purpose
Verify frontend loads without errors

### Steps

#### 1. Open Browser
```
http://localhost:5173/
```

#### 2. Login
- Email: `test@example.com`
- Password: `testpass123`
- Click Login

#### 3. Navigate to Inference Page
- Click "Inference" in navigation (or navigate to `/inference`)

### Expected Result
‚úÖ Page loads
‚úÖ No console errors (F12 ‚Üí Console)
‚úÖ Model dropdown populated
‚úÖ "Upload Image" button visible

### Check Browser Console
```
F12 ‚Üí Console tab
Should show: No red errors
May show: Some CORS warnings (OK if API works)
```

---

## üñºÔ∏è Test 6: Image Upload Flow

### Purpose
Test image upload and preview

### Steps

#### 1. Create Test Image
Create a simple test image or use an existing one (PNG/JPG)
- Size: 32√ó32 pixels (matches model input)
- Or any size (will be auto-resized)

#### 2. Upload Image
- Click "Upload Image" button
- Select the test image file
- Verify preview appears on left side

### Expected Result
‚úÖ Image file selected
‚úÖ File name shown below button
‚úÖ Image preview displayed
‚úÖ Preview correctly resized

---

## üöÄ Test 7: Run Inference from Frontend

### Purpose
Full end-to-end inference pipeline

### Steps

#### 1. Select Model
- Dropdown: "TestCNN"

#### 2. Select Version
- Dropdown: "Version 1"

#### 3. Upload Test Image
- Click "Upload Image"
- Select your test image

#### 4. Run Inference
- Click "Run Inference" button
- Watch loading spinner

### Expected Results

**During Inference**:
‚úÖ Button shows "Running..." with spinner
‚úÖ Page is responsive (not frozen)
‚úÖ Processing completes in <2 seconds

**After Inference**:
‚úÖ Results section appears
‚úÖ Shows:
  - Processing Time: ~245 ms
  - Output Shape: 1 √ó 10
  - Model Configuration box
‚úÖ Three tabs available:
  - Feature Maps
  - Activations
  - Layer Details

---

## üìä Test 8: Feature Maps Visualization

### Purpose
Verify heatmap rendering

### Steps

#### 1. Click "Feature Maps" Tab
- Should already be selected after inference

#### 2. Verify Canvas Renders
- Should see colorful heatmap image
- Colors: Blue ‚Üí Green ‚Üí Yellow ‚Üí Red
- Size: 256√ó256 pixels

#### 3. Select Different Layers
- Dropdown: Change between layers
- Each layer should show different heatmap
- Canvas updates when selection changes

#### 4. Check Layer Info Panel
- Shows layer name
- Shows output shape
- Shows activation statistics (min, max, mean, std, median)
- Shows color scale legend

### Expected Result
‚úÖ Heatmap renders correctly
‚úÖ Colors vary by activation value
‚úÖ Layer selection works
‚úÖ Statistics display correctly
‚úÖ No visual glitches

---

## üìà Test 9: Activation Visualizer

### Purpose
Verify activation statistics and health analysis

### Steps

#### 1. Click "Activations" Tab

#### 2. Verify Global Statistics
- Shows: Global Min, Max, Range, Total Layers
- Numbers make sense (e.g., Range > 0)

#### 3. Check Layer Table
- Lists all 7 layers
- Columns: Layer, Type, Min, Max, Mean, Std, Activation Bar, Status
- Each row has complete data

#### 4. Check Status Indicators
- Most show: ‚úì Normal (green)
- Some may show: ‚ö† Dead (red) - acceptable for test
- Some may show: ‚ö† Saturated (orange) - acceptable for test

#### 5. Check Activation Bars
- Each layer has colored bar
- Bar fills proportionally to mean activation
- Colors: Blue, Green, Yellow, Red gradients

#### 6. Check Legend
- Shows three status types with descriptions
- Color explanations visible

### Expected Result
‚úÖ All statistics display
‚úÖ No NaN or undefined values
‚úÖ Table scrollable if needed
‚úÖ Color coding consistent
‚úÖ Status indicators accurate

---

## üìã Test 10: Layer Details Tab

### Purpose
Verify detailed layer statistics

### Steps

#### 1. Click "Layer Details" Tab

#### 2. Verify Table Displays
- Headers: Layer, Type, Output Shape, Min, Max, Mean, Std
- All 7 rows present
- Data matches other tabs

#### 3. Verify Values
- Min < Max (always true)
- Mean between Min and Max
- Std > 0 (usually)
- Output Shape non-empty

#### 4. Check Formatting
- Numbers formatted to 4 decimal places
- Shapes formatted as "1 √ó 32 √ó 30 √ó 30"
- No scientific notation (e.g., 1e-5)

### Expected Result
‚úÖ All data displays correctly
‚úÖ Table is readable
‚úÖ Numbers properly formatted
‚úÖ No missing values

---

## üîÑ Test 11: Different Model Test

### Purpose
Verify pipeline works with different architectures

### Steps

#### 1. Create Second Model
```
POST /api/v1/models
{
  "name": "TestLinear",
  "description": "Simple linear model",
  "model_type": "classification"
}
```

#### 2. Add Version with Different Architecture
```
POST /api/v1/models/{id}/versions
{
  "architecture": {
    "layers": [
      {"type": "Flatten", "params": {"start_dim": 1}},
      {"type": "Linear", "params": {"in_features": 3072, "out_features": 128}},
      {"type": "ReLU", "params": {"inplace": false}},
      {"type": "Linear", "params": {"in_features": 128, "out_features": 10}}
    ]
  },
  "input_shape": [1, 3, 32, 32]
}
```

#### 3. Test Inference
- Select new model
- Upload same image
- Run inference

### Expected Result
‚úÖ Different model loads
‚úÖ Different number of layers (4 vs 7)
‚úÖ Inference completes
‚úÖ Results display correctly

---

## ‚ö° Test 12: Error Handling

### Purpose
Verify system handles errors gracefully

### Test Case 1: Missing Model
```powershell
curl http://localhost:8000/api/v1/inference/invalid-id/config `
  -H "Authorization: Bearer $TOKEN"

# Expected: 404 Not Found
```

### Test Case 2: Invalid Image Format
- Try uploading non-image file
- Should show error message

### Test Case 3: Unauthorized Access
```powershell
curl http://localhost:8000/api/v1/inference/run `
  -H "Content-Type: application/json" `
  -d '{"version_id": "...", "input_data": [...]}'
# No auth header

# Expected: 403 Forbidden or 401 Unauthorized
```

### Expected Result
‚úÖ 404 for missing resources
‚úÖ 403 for unauthorized access
‚úÖ User-friendly error messages
‚úÖ No server crashes

---

## üìù Test 13: Console Check

### Purpose
Verify no critical errors in browser/server

### Steps

#### 1. Browser Console (F12)
- No red error messages
- Warnings acceptable
- Network tab shows successful requests

#### 2. Backend Terminal
- No exception traces
- Inference endpoint called: "POST /inference/run"
- Response times logged

#### 3. Check Logs
```powershell
# Backend should show:
# INFO:     "POST /api/v1/inference/run HTTP/1.1" 200
```

### Expected Result
‚úÖ No critical errors
‚úÖ All requests successful (200, 201, 204)
‚úÖ 0 failing API calls
‚úÖ Clean console output

---

## üéØ Test 14: Performance Check

### Purpose
Verify system performance

### Metrics to Track

#### Backend Performance
- Inference time: <500ms (target: <250ms)
- Model building time: <1s (first time, then cached)
- API response: <100ms overhead

#### Frontend Performance
- Page load: <2 seconds
- Visualization rendering: <500ms
- No UI freezing

#### Test Command
```powershell
# Run inference 3 times and record times
Measure-Command {
  curl http://localhost:8000/api/v1/inference/run `
    -H "Authorization: Bearer $TOKEN" `
    -H "Content-Type: application/json" `
    -d '{...}'
}
```

### Expected Result
‚úÖ Average time < 1 second
‚úÖ Consistent performance across runs
‚úÖ No memory leaks (RAM stable)

---

## üìä Test 15: Data Validation

### Purpose
Verify API responses contain correct data

### Checks

#### 1. InferenceResponse Structure
```json
{
  "version_id": "string",
  "output": [number, ...],
  "output_shape": [number, ...],
  "layer_outputs": [LayerOutput, ...],
  "processing_time": number
}
```

#### 2. LayerOutput Structure
```json
{
  "layer_name": "string",
  "layer_type": "string",
  "output_shape": [number, ...],
  "activation_stats": {
    "min": number,
    "max": number,
    "mean": number,
    "std": number,
    "median": number
  },
  "output_data": [number, ...]
}
```

#### 3. Validate Values
- No NaN or Infinity values
- Min ‚â§ Mean ‚â§ Max
- Std ‚â• 0
- Processing time > 0
- Layer outputs non-empty

### Expected Result
‚úÖ Response structure valid
‚úÖ All fields present
‚úÖ No invalid values
‚úÖ Data types correct

---

## üìã Test Summary Checklist

| Test | Status | Notes |
|------|--------|-------|
| Backend Health | ‚¨ú | |
| Authentication | ‚¨ú | |
| Model Creation | ‚¨ú | |
| Model Config | ‚¨ú | |
| Backend Inference | ‚¨ú | |
| Frontend Components | ‚¨ú | |
| Image Upload | ‚¨ú | |
| Frontend Inference | ‚¨ú | |
| Feature Maps | ‚¨ú | |
| Activations Tab | ‚¨ú | |
| Layer Details Tab | ‚¨ú | |
| Different Model | ‚¨ú | |
| Error Handling | ‚¨ú | |
| Console Errors | ‚¨ú | |
| Performance | ‚¨ú | |
| Data Validation | ‚¨ú | |

---

## üéâ Final Checklist

When all tests pass:

- [ ] No server crashes
- [ ] No console errors
- [ ] All visualizations render
- [ ] Inference completes
- [ ] Error handling works
- [ ] Performance acceptable
- [ ] Data validation passes

---

## üêõ Troubleshooting

### Issue: 404 Model Not Found
**Solution**: Make sure you saved the MODEL_ID from step 3

### Issue: Image upload doesn't work
**Solution**: Check file format is PNG/JPG, and size < 50MB

### Issue: Inference times out
**Solution**: Try with smaller model or restart backend

### Issue: Visualizations don't render
**Solution**: Check browser console for errors, refresh page

### Issue: Authorization fails
**Solution**: Make sure TOKEN is valid and not expired

---

## ‚úÖ Success Criteria

Your integration testing is **COMPLETE** when:

1. ‚úÖ All 15 tests pass
2. ‚úÖ No critical errors in console
3. ‚úÖ All visualizations render
4. ‚úÖ Inference pipeline end-to-end works
5. ‚úÖ Performance acceptable (<1s total)
6. ‚úÖ Error handling graceful

---

## üöÄ Next Steps After Testing

Once integration testing complete:

1. Deploy to production
2. Set up monitoring
3. Enable caching for performance
4. Add batch inference support
5. Implement model export functionality
6. Add more visualization options

---

## üìû Support

If tests fail:
1. Check backend is running: `uvicorn backend.main:app --reload`
2. Check frontend is running: `npm run dev`
3. Check MongoDB is running
4. Check network connectivity
5. Review error messages in console

Good luck! üöÄ
